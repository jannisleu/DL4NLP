{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"25bdacaf37cf4a839b67c3a19948eafe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99631eb3938f4c05922f2f5122cda309","IPY_MODEL_d14a10daee274de3849feac1b2d5ba24","IPY_MODEL_fbb63ef728e54c7183fcb1023168ea14"],"layout":"IPY_MODEL_06cbcf17bba0479fbe03d8c6afbff6a7"}},"99631eb3938f4c05922f2f5122cda309":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb87e58d7be54724a9c8b7ebc50b1fc7","placeholder":"​","style":"IPY_MODEL_58dcfcb4b95242c4a2b9a8bd9a1aa2a3","value":"  0%"}},"d14a10daee274de3849feac1b2d5ba24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e254a7443814faca3d369d4d74ae972","max":63,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9757ed1c11c94afaa4464ae24ca51563","value":0}},"fbb63ef728e54c7183fcb1023168ea14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a274a3adeb447a2a2cbcca5dba9825f","placeholder":"​","style":"IPY_MODEL_03d1b1553884472cb1767206c215806d","value":" 0/63 [00:00&lt;?, ?it/s]"}},"06cbcf17bba0479fbe03d8c6afbff6a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb87e58d7be54724a9c8b7ebc50b1fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58dcfcb4b95242c4a2b9a8bd9a1aa2a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e254a7443814faca3d369d4d74ae972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9757ed1c11c94afaa4464ae24ca51563":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a274a3adeb447a2a2cbcca5dba9825f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03d1b1553884472cb1767206c215806d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3693a3a127a54b00a75b3fc7d4620d1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc272e7bff144261a02ee01b25fbd252","IPY_MODEL_6699c8093f924db4acab78d5f948da4d","IPY_MODEL_9dbb9854e18f47ea8a8a4ae5648b4b52"],"layout":"IPY_MODEL_c6e39e6f793044e4b44843a69eeca874"}},"fc272e7bff144261a02ee01b25fbd252":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85ac35489807450081183471b7b925b0","placeholder":"​","style":"IPY_MODEL_5963a5df31514340bbee80c02c313c5c","value":"100%"}},"6699c8093f924db4acab78d5f948da4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6de909cef59b4a1e8858e75601496d5b","max":1246263,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a85436040b14a96befde5b4aeaa23d6","value":1246263}},"9dbb9854e18f47ea8a8a4ae5648b4b52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c20451e5310541f3bc7337bdf1ee32fc","placeholder":"​","style":"IPY_MODEL_182d5ea30ce64f6790ec86ed5364b3a7","value":" 1246263/1246263 [00:15&lt;00:00, 89372.68it/s]"}},"c6e39e6f793044e4b44843a69eeca874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85ac35489807450081183471b7b925b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5963a5df31514340bbee80c02c313c5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6de909cef59b4a1e8858e75601496d5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a85436040b14a96befde5b4aeaa23d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c20451e5310541f3bc7337bdf1ee32fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"182d5ea30ce64f6790ec86ed5364b3a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42f4e057bcd844bdaa3732865b785cc7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77fec05eea11467ba43efc8ab25761eb","IPY_MODEL_f12a9a4086794c88b312f8cff39a87b5","IPY_MODEL_4a75405c25b648e98cde2ca7fb04a6d7"],"layout":"IPY_MODEL_f2253afeb91b4af8b270c6e3be6852ba"}},"77fec05eea11467ba43efc8ab25761eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b07298565fbb4464931bc9dac7578bf5","placeholder":"​","style":"IPY_MODEL_7bfdd9b1c5f34adeb24e0f730d5a4644","value":"100%"}},"f12a9a4086794c88b312f8cff39a87b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e64627bc01d4759a7922d3e40975706","max":1228546,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c4df115bca44256a4426085a75f3836","value":1228546}},"4a75405c25b648e98cde2ca7fb04a6d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4106e507b3c493595d5da513420c688","placeholder":"​","style":"IPY_MODEL_df1221de7ebd4b058b3e2e0e68c579aa","value":" 1228546/1228546 [00:15&lt;00:00, 101975.99it/s]"}},"f2253afeb91b4af8b270c6e3be6852ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b07298565fbb4464931bc9dac7578bf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bfdd9b1c5f34adeb24e0f730d5a4644":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e64627bc01d4759a7922d3e40975706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c4df115bca44256a4426085a75f3836":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4106e507b3c493595d5da513420c688":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df1221de7ebd4b058b3e2e0e68c579aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abbf33d98b0c4b008923109c888efb6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aaaff47cb59c4e7184fce3393b88b2e6","IPY_MODEL_20533028cf2e42c2a4e9a3ec0375698c","IPY_MODEL_3442239bf7674645b3fa779c8050ae02"],"layout":"IPY_MODEL_8b2a79a524cd492ca720e38f59c234b7"}},"aaaff47cb59c4e7184fce3393b88b2e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f5d6424c3194ad196f5f27a3f86f75f","placeholder":"​","style":"IPY_MODEL_f8db417f291d4d07a718bcf5e5918179","value":"100%"}},"20533028cf2e42c2a4e9a3ec0375698c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7044e4cdf86b4cf585dfc0f58cb90d42","max":258317,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c60ae0dcd15d4fa58c357462cce78def","value":258317}},"3442239bf7674645b3fa779c8050ae02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_012eaa7145b94e8ba64e79c66f2f2ca7","placeholder":"​","style":"IPY_MODEL_59ff43c6e09c4e05a2bd5b2aa7bf2046","value":" 258317/258317 [00:01&lt;00:00, 183540.29it/s]"}},"8b2a79a524cd492ca720e38f59c234b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f5d6424c3194ad196f5f27a3f86f75f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8db417f291d4d07a718bcf5e5918179":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7044e4cdf86b4cf585dfc0f58cb90d42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c60ae0dcd15d4fa58c357462cce78def":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"012eaa7145b94e8ba64e79c66f2f2ca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59ff43c6e09c4e05a2bd5b2aa7bf2046":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a98adb872784e21b4d0babb3f57e969":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9307ca803bcf4e06a69ccd0e45b7f606","IPY_MODEL_b13b4c16d0ca4b4297d2e1c652f2a035","IPY_MODEL_c31ceb2aa6cc4716856906c0b1ad07c5"],"layout":"IPY_MODEL_3f712745b2e04e109acf93ab1e3a20a0"}},"9307ca803bcf4e06a69ccd0e45b7f606":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6855a8eca78f474593204c4938c2de78","placeholder":"​","style":"IPY_MODEL_e1347ff501a34f718d74cd948d70a448","value":"100%"}},"b13b4c16d0ca4b4297d2e1c652f2a035":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5b64f77f88d42f9b4be9402a37b3081","max":257768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f407d9ea5d1844ed910344c4b89910f8","value":257768}},"c31ceb2aa6cc4716856906c0b1ad07c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b8609e2cf304b22bbdb5b5ed668d69d","placeholder":"​","style":"IPY_MODEL_2e16fe40207547f680b17cb65a76732a","value":" 257768/257768 [00:00&lt;00:00, 584893.97it/s]"}},"3f712745b2e04e109acf93ab1e3a20a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6855a8eca78f474593204c4938c2de78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1347ff501a34f718d74cd948d70a448":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5b64f77f88d42f9b4be9402a37b3081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f407d9ea5d1844ed910344c4b89910f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b8609e2cf304b22bbdb5b5ed668d69d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e16fe40207547f680b17cb65a76732a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9484810d8644af393d5e31682e3c0a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_544aa0bd96a44f45b07e62ad75db1d8f","IPY_MODEL_34c452c850e04cd3bb29188dc1f5dde8","IPY_MODEL_19dd66a9249c4128b21191b446b5e2e5"],"layout":"IPY_MODEL_b017236c355b419699ab39805a6682fd"}},"544aa0bd96a44f45b07e62ad75db1d8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba3850a8e90740ac98d0c5287c93c0b1","placeholder":"​","style":"IPY_MODEL_0866455324ac487f8751aeb21200c23f","value":"Loss: 4.078:   1%"}},"34c452c850e04cd3bb29188dc1f5dde8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_638f3168f87d429e9f1f43d41875f257","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f316410532945fe84f3493ee731bff4","value":3}},"19dd66a9249c4128b21191b446b5e2e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66b679345dcf44e996a81e72de3c86f2","placeholder":"​","style":"IPY_MODEL_101ac33467f3417fa2bddbe32962586a","value":" 3/300 [00:05&lt;07:22,  1.49s/it]"}},"b017236c355b419699ab39805a6682fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba3850a8e90740ac98d0c5287c93c0b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0866455324ac487f8751aeb21200c23f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"638f3168f87d429e9f1f43d41875f257":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f316410532945fe84f3493ee731bff4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66b679345dcf44e996a81e72de3c86f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"101ac33467f3417fa2bddbe32962586a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"1I_WVtoi81lC"},"source":["<h1> Language Modeling <h1>"]},{"cell_type":"markdown","metadata":{"id":"8L-ucuhN9HfE"},"source":["After having studied word embeddings and text classification in the previous notebooks, we will now focus on language modeling. </br>\n","\n","Word prediction is a Natural Language Processing - NLP application concerned with predicting the next word given the preceding text. Auto-complete or suggested responses are popular types of language prediction tasks. But you may wonder, what does word predction have to do with language modeling? The idea is that by training a deep neural network to predict what text is to follow, the network will get an understanding, or a model, of the language that it was trained on. </br>\n","\n","The first step towards language prediction is the selection of a language or word prediction model.\n","Broadly speaking, there exist two models you can use to develop a next-word- predictor model:\n","</br> 1) Statistical N-gram models or\n","</br> 2) (Deep) Neural models."]},{"cell_type":"markdown","metadata":{"id":"OyhaqQQD9OM-"},"source":["**0. Task** (0 points)  </br>\n","Before diving into the tasks, here are a couple of imports we will later use."]},{"cell_type":"code","metadata":{"id":"b5ztGGH--rfg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"acbce83b-af79-40eb-fa17-345cd8147997","executionInfo":{"status":"ok","timestamp":1703276819727,"user_tz":-60,"elapsed":12547,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["!pip install boltons -q"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/195.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/195.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/195.3 kB\u001b[0m \u001b[31m237.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/195.3 kB\u001b[0m \u001b[31m295.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/195.3 kB\u001b[0m \u001b[31m373.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/195.3 kB\u001b[0m \u001b[31m625.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.3/195.3 kB\u001b[0m \u001b[31m855.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"GJ_sI6SI-UIR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"26754441-e7d2-41ef-f18c-fbc5cde40c72","executionInfo":{"status":"ok","timestamp":1703276828691,"user_tz":-60,"elapsed":8970,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["import string\n","from pathlib import Path\n","from textwrap import wrap\n","\n","import numpy as np\n","import pandas as pd\n","from boltons.iterutils import windowed\n","#from tqdm import tqdm_notebook\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","from nltk.util import ngrams\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.dataset import random_split\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tXUE8n_v-UIs","outputId":"de72d014-4731-439c-8a43-3ee95a31efd5","executionInfo":{"status":"ok","timestamp":1703276828691,"user_tz":-60,"elapsed":19,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["device_word = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device_char = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device_word"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"BZy9leGX-cNk"},"source":["<h1>Word and Text Generation</h1>\n","\n","In this notebook, we will do two things:\n","1.   Build a Recurrent Neural Network (RNN), that can learn how english *characters* are combined.\n","2.   Build an RNN, that can learn how english *words* are combined.\n","\n","To achieve this, we are going to do the following steps:\n","1.   Load the Data\n","2.   Preprocess the Data for character-level generation\n","3.   Preprocess the Data for word-level generation\n","4.   Build the RNN\n","5.   Apply the RNN to the Data from Step 2\n","6.   Apply the RNN to the Data from Step 3\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"atLUvUh-MbuZ"},"source":["<h2>1. Load the Data</h2>\n","\n","Our Dataset consists of multiple texts about weight loss (referring to body weight, not a weight of a Neural Network)."]},{"cell_type":"code","metadata":{"id":"NKw4lpSO-UI2","executionInfo":{"status":"ok","timestamp":1703276834813,"user_tz":-60,"elapsed":2143,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"df5b0f1d-ee91-4188-cbe5-52c411cd3bef"},"source":["# The input texts can be found here:\n","DATA_PATH = 'data/weight_loss/articles.jsonl'\n","if not Path(DATA_PATH).is_file():\n","    gdd.download_file_from_google_drive(\n","        file_id='1mafPreWzE-FyLI0K-MUsXPcnUI0epIcI',\n","        dest_path='data/weight_loss/weight_loss_articles.zip',\n","        unzip=True,\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading 1mafPreWzE-FyLI0K-MUsXPcnUI0epIcI into data/weight_loss/weight_loss_articles.zip... Done.\n","Unzipping...Done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KtTqxTN-byG","outputId":"825b3102-9070-4fd7-b2ce-6d7e67b7cc71","executionInfo":{"status":"ok","timestamp":1703276837339,"user_tz":-60,"elapsed":248,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["# Let's print out the first article.\n","print(pd.read_json(DATA_PATH).text.str.lower().tolist()[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["weight gaining is a common problem around the world. in developed country, it is the most common problem. in this article, i am not going to show you some advance and magical technique which will make you slim overnight. i am going to show you tips on the basis of real facts which works. in this article, i will give you how to tips, which will help you to lose weight. are you ready?\n","calories requirement\n","first thing you need to understand is why you gain weight. why? whenever you eat or drink something, you will get some calories. when you think about weight, everything revolves around calories.\n","whatever you do, will burn some calories no matter how small work it is or just a movement of your body. your body burns thousands of calories in one day.\n","if you are getting more calories than needed, you will gain weight. if you are getting fewer calories than needed, you will lose weight. so for losing weight, you need to know how much calorie your body required.\n","find require calories for your body\n","how will you know that how much calories your body require? well, there is a formula to find out that but you don't need to understand that. just go tohttp://www.freedieting.com/tools/calorie_calculator.htm. enter the details and you will come to know how much calories require for your body.\n","now you know how much calories your body needs. you just need to balance between require and burning calories. there are two ways you can lose weight.\n","you are not going to use only one. you will use mix of both. you will consume less calories and burn more calories. so keep a track of how much calories you take. also do some more exercise. not too much just a little more. so you burn more calories.\n","you are controlling calories in two ways. losing little more calories and getting little less calories. so you will definitely lose weight.\n","take less calories\n","burn more calories\n"]}]},{"cell_type":"markdown","metadata":{"id":"QXP6jn83Orbg"},"source":["<h2>2. Preprocess the data for character-level generation</h2>\n","\n","As you can see in the cell above, it is pretty tedious to access the data. In the next few steps, we'll help you and the network to access the data more easily."]},{"cell_type":"code","metadata":{"id":"_0lWXlh6V-GC"},"source":["def remove_unprintable_chars(all_chars_windowed):\n","\n","  not_printbl_chars=[]\n","  filtered_chars=[]\n","  printbl=True\n","\n","  for sequence in tqdm(all_chars_windowed):\n","    printbl=True\n","\n","    for char in sequence:\n","      if not(char in string.printable):\n","        printbl=False\n","        not_printbl_chars+=[char]\n","    if printbl==True:\n","      filtered_chars+=[sequence]\n","\n","  return filtered_chars"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fe1X3_lY-UI9"},"source":["def textlist_generator(path):\n","  return pd.read_json(path).text.str.lower().tolist()\n","\n","def load_data_char(path, sequence_length=125):\n","\n","    texts = textlist_generator(path)\n","    chars_windowed = [list(windowed(text, sequence_length)) for text in texts]\n","    all_chars_windowed = [sublst for lst in chars_windowed for sublst in lst]\n","    filtered_chars = remove_unprintable_chars(all_chars_windowed)\n","\n","    return filtered_chars\n","\n","def set_of_chars_in(sequences):\n","    return {sublst for lst in sequences for sublst in lst}\n","\n","def create_char2idx(sequences):\n","    set_of_chars = set_of_chars_in(sequences)\n","    return {char: idx for idx, char in enumerate(sorted(set_of_chars))}\n","\n","def encode_sequence(sequence, char2idx):\n","    return [char2idx[char] for char in sequence]\n","\n","def encode_sequences(sequences, char2idx):\n","    return np.array([\n","        encode_sequence(sequence, char2idx)\n","        for sequence in tqdm(sequences)\n","    ])\n","\n","class Sequences(Dataset):\n","    def __init__(self, path, sequence_length=125):\n","        self.sequences = load_data_char(DATA_PATH, sequence_length=sequence_length)\n","        self.vocab_size = len(set_of_chars_in(self.sequences))\n","        self.char2idx = create_char2idx(self.sequences)\n","        if self.char2idx is not None:\n","          print(\"Initialized properly.\")\n","        else:\n","          print(\"Not initialized properly.\")\n","        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n","        self.encoded = encode_sequences(self.sequences, self.char2idx)\n","\n","    def __getitem__(self, i):\n","        return self.encoded[i, :-1], self.encoded[i, 1:]\n","\n","    def __len__(self):\n","        return len(self.encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d2iIT4s4qfrY"},"source":["The following three tasks will help you to understand the code better."]},{"cell_type":"markdown","metadata":{"id":"ZIYI0mHadM6p"},"source":["**2.1** (1 Point) <br>\n","\n","Describe the variable `chars_windowed`. What does it contain?"]},{"cell_type":"markdown","metadata":{"id":"xViMgbwEeU_u"},"source":["**Your answer goes here**"]},{"cell_type":"markdown","metadata":{"id":"Wev3uOKRdq5I"},"source":["**2.2** (1 Point) <br>\n","Describe the variable `all_chars_windowed`. What does it contain?"]},{"cell_type":"markdown","metadata":{"id":"PYQulPqkeTmv"},"source":["**Your answer goes here**"]},{"cell_type":"markdown","metadata":{"id":"GB7cFHZ4Z_Gh"},"source":["**2.3** (1 Point) <br>\n","Explain shortly, what the function `remove_unprintable_chars(all_chars_windowed)`does. We do not want a step by step explaination, just describe the general idea."]},{"cell_type":"markdown","metadata":{"id":"OO5EoJXFanlq"},"source":["**Your answer goes here**"]},{"cell_type":"markdown","source":["**2.4** (1 Point) <br>\n","Briefly describe in your own words what the class variable `self.sequences` will contain and why this is needed."],"metadata":{"id":"F2jx3FNXW2L9"}},{"cell_type":"markdown","source":["**Your answer goes here**"],"metadata":{"id":"h72dqQpxXbLe"}},{"cell_type":"markdown","metadata":{"id":"aZHxjVRgbQgs"},"source":["Now lets load our char_dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQh-02Ye89Id","outputId":"fe4ada86-fdad-487a-9825-e8f0fa1bd817","executionInfo":{"status":"ok","timestamp":1703276872810,"user_tz":-60,"elapsed":6967,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["sequence_length_char=int(input(\"Choose your sequence_length_char and hit enter (for this task, we chose 128): \"))\n","if sequence_length_char<=1:\n","  print(\"1 or less is not a valid sequence length. Your model will not learn anything from just one word at a time. The sequence lenght of 128 has been chosen for you.\")\n","  sequence_length_char=128"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Choose your sequence_length_char and hit enter (for this task, we chose 128): 128\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["3693a3a127a54b00a75b3fc7d4620d1c","fc272e7bff144261a02ee01b25fbd252","6699c8093f924db4acab78d5f948da4d","9dbb9854e18f47ea8a8a4ae5648b4b52","c6e39e6f793044e4b44843a69eeca874","85ac35489807450081183471b7b925b0","5963a5df31514340bbee80c02c313c5c","6de909cef59b4a1e8858e75601496d5b","4a85436040b14a96befde5b4aeaa23d6","c20451e5310541f3bc7337bdf1ee32fc","182d5ea30ce64f6790ec86ed5364b3a7","42f4e057bcd844bdaa3732865b785cc7","77fec05eea11467ba43efc8ab25761eb","f12a9a4086794c88b312f8cff39a87b5","4a75405c25b648e98cde2ca7fb04a6d7","f2253afeb91b4af8b270c6e3be6852ba","b07298565fbb4464931bc9dac7578bf5","7bfdd9b1c5f34adeb24e0f730d5a4644","3e64627bc01d4759a7922d3e40975706","5c4df115bca44256a4426085a75f3836","d4106e507b3c493595d5da513420c688","df1221de7ebd4b058b3e2e0e68c579aa"]},"id":"BZxQzaME-UJG","outputId":"d5ec3fbc-917e-4053-d5d7-d9e0a677036a","executionInfo":{"status":"ok","timestamp":1703276933024,"user_tz":-60,"elapsed":57632,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["dataset_char = Sequences(DATA_PATH, sequence_length=sequence_length_char)\n","len(dataset_char)\n","train_loader_char = DataLoader(dataset_char, batch_size=4096)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1246263 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3693a3a127a54b00a75b3fc7d4620d1c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Initialized properly.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1228546 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42f4e057bcd844bdaa3732865b785cc7"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"x9feqYMs_vYS"},"source":["<h2>3. Preprocess the data for word-level generation</h2>"]},{"cell_type":"markdown","metadata":{"id":"OcDtOiP7A4oj"},"source":["We now have to do the same preprocessing steps for our word-level-model. But dont worry, it works quite similar to the character-level-preprocessing steps. In the following, there are a couple of tasks that will guide you through the process.\n"]},{"cell_type":"markdown","metadata":{"id":"5mqFYOX7Ukw9"},"source":["**3.1 Tokenize** (1 Point)<br>\n","Complete the function `tokenize` which gets multiple texts as input and returns a list that contains a list of word-level-tokens for each text (so that in the end we have a list of lists)."]},{"cell_type":"code","metadata":{"id":"Fk6WT1WYU-he"},"source":["def tokenize(texts):\n","    texts_tokens=[]\n","    # Your code goes here\n","\n","\n","    return texts_tokens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OonqPi-lWlh8"},"source":["**3.2 Unprintable sequences** (4 Points) <br>\n","Do you remember the task 2.3? Apply the same functionality, but keep in mind, that we are now working on the basis of words, not chars.\n","Adapt the function from task 2.3 so that it now works with words. Unprintable sequences should still be deleted. Write your solution into the function `remove_unprintable_sequences`."]},{"cell_type":"code","metadata":{"id":"drlYnhUfX6g6"},"source":["def remove_unprintable_sequences(all_words_windowed):\n","  filtered_words = []\n","  #  Your code goes here\n","\n","\n","  return filtered_words"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Y5YSvESboYU"},"source":["We now put all the functions you provided together."]},{"cell_type":"code","metadata":{"id":"fKCVbIY0Tqfp"},"source":["def load_data_word(path, sequence_length=5):\n","\n","    # Generate a list of texts from the dataset\n","    texts = textlist_generator(path)\n","    texts = tokenize(texts)\n","    words_windowed = [list(windowed(text, sequence_length)) for text in texts]\n","    all_words_windowed = [sublst for lst in words_windowed for sublst in lst]\n","    filtered_words = remove_unprintable_sequences(all_words_windowed)\n","\n","    return filtered_words"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3kZ3bKU1C4xm"},"source":["****"]},{"cell_type":"markdown","metadata":{"id":"BuUnW1w8EMo5"},"source":["**3.3** (1 Point) </br>\n","Write a function that returns a set of all the words accross a sequence. More specifically, the input to this function or the sequence will be a list of tuples that contain tokens. The output should be a set (!) of words. Find where it is used to understand what exactly we mean by set."]},{"cell_type":"code","metadata":{"id":"i0kyCSQOEWuW","colab":{"base_uri":"https://localhost:8080/","height":128},"outputId":"a9984369-258d-4afd-df05-d6e30f6d26f9"},"source":["def set_of_words_in(sequences):\n","    # Your code goes here\n","\n","\n","    return set_of_words"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-5fa553f7182e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return {#YOUR CODE HERE}\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}]},{"cell_type":"markdown","metadata":{"id":"B102b9njEe7U"},"source":["**3.4** (1 Point) </br>\n","Write a function that returns a dictionary containing the set of words indentified in task 3.3 and assigns an index to each of them."]},{"cell_type":"code","metadata":{"id":"Sxj_ahttEzJl"},"source":["def create_word2idx(sequences):\n","    set_of_words = set_of_words_in(sequences)\n","    dic = {}\n","\n","    # Your code goes here\n","\n","\n","    return dic"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZqaN_y1GE5co"},"source":["**3.5** (1 Point)</br>\n","Create a function `encode_sequence`, that transforms the words of a list of words, here: `sequence`, into their equivalent index from the dictionary `word2index`. This shall return a list again."]},{"cell_type":"code","metadata":{"id":"Sa2RstHQFLux"},"source":["def encode_sequence(sequence, word2idx):\n","    enc_seq = []\n","    # Your code goes here\n","\n","\n","    return enc_seq"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p7dNIOZKGmt7"},"source":["**3.6** (1 Point) </br>\n","Complete the function `encode_sequences` that generates a numpy array, with the encoded sequence of all the sequences."]},{"cell_type":"code","metadata":{"id":"FVK1-y5ZGsDH"},"source":["def encode_sequences(sequences, word2idx):\n","    # Your code goes here\n","\n","\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nNi7RhbUFs1i"},"source":["In the next code snippet we call all the functions you defined above. (You don't have to do anything here, just run the cell)"]},{"cell_type":"code","metadata":{"id":"iRJ1D6OtFrd7"},"source":["class Sequences(Dataset):\n","    def __init__(self, path, sequence_length=30):\n","        self.sequences = load_data_word(DATA_PATH, sequence_length=sequence_length)\n","        self.vocab_size = len(set_of_words_in(self.sequences))\n","        self.word2idx = create_word2idx(self.sequences)\n","        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n","        self.encoded = encode_sequences(self.sequences, self.word2idx)\n","\n","    def __getitem__(self, i):\n","        return self.encoded[i, :-1], self.encoded[i, 1:]\n","\n","    def __len__(self):\n","        return len(self.encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nK4PRO9L7uOK","outputId":"4d6f46d3-45ec-45b0-8f1d-e8c261a22e55","executionInfo":{"status":"ok","timestamp":1703277039826,"user_tz":-60,"elapsed":2579,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["sequence_length_words=int(input(\"Choose your sequence_length_words and hit enter (for this task, we chose 10): \"))\n","if sequence_length_words<=1:\n","  print(\"1 or less is not a valid sequence length. Your model will not learn anything from just one word at a time. The sequence lenght of 10 has been chosen for you.\")\n","  sequence_length_words=10"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Choose your sequence_length_words and hit enter (for this task, we chose 10): 10\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["abbf33d98b0c4b008923109c888efb6e","aaaff47cb59c4e7184fce3393b88b2e6","20533028cf2e42c2a4e9a3ec0375698c","3442239bf7674645b3fa779c8050ae02","8b2a79a524cd492ca720e38f59c234b7","0f5d6424c3194ad196f5f27a3f86f75f","f8db417f291d4d07a718bcf5e5918179","7044e4cdf86b4cf585dfc0f58cb90d42","c60ae0dcd15d4fa58c357462cce78def","012eaa7145b94e8ba64e79c66f2f2ca7","59ff43c6e09c4e05a2bd5b2aa7bf2046","2a98adb872784e21b4d0babb3f57e969","9307ca803bcf4e06a69ccd0e45b7f606","b13b4c16d0ca4b4297d2e1c652f2a035","c31ceb2aa6cc4716856906c0b1ad07c5","3f712745b2e04e109acf93ab1e3a20a0","6855a8eca78f474593204c4938c2de78","e1347ff501a34f718d74cd948d70a448","d5b64f77f88d42f9b4be9402a37b3081","f407d9ea5d1844ed910344c4b89910f8","2b8609e2cf304b22bbdb5b5ed668d69d","2e16fe40207547f680b17cb65a76732a"]},"id":"xSV6H2z9IqV5","outputId":"4518a99c-7d0c-4d8c-b498-7f3027e7bf44","executionInfo":{"status":"ok","timestamp":1703277049359,"user_tz":-60,"elapsed":4602,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["dataset_word = Sequences(DATA_PATH, sequence_length=sequence_length_words)\n","len(dataset_word)\n","train_loader_word = DataLoader(dataset_word, batch_size=4096)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/258317 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abbf33d98b0c4b008923109c888efb6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/257768 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a98adb872784e21b4d0babb3f57e969"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"lRyoQrbvtdLy"},"source":["<h2>4. char-RNN: Character-level text generation</h2>\n","\n","Read this [Blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) to understand the idea behind this approach. An LSTM is used to generate new texts on character level. To make it easier for you in this notebook, we are building an RNN with Gated Recurrent Units (GRU). GRUs work very similar  to LSTMs, but they are easier to handle. For a full comparison of these two, have a look at [this](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/)."]},{"cell_type":"markdown","source":["**4.1** (1 Point)\n","<br>\n","Summarize in one sentence which drawbacks both GRUs and LSTMs try to overcome that are faced when using a Vanilla RNN."],"metadata":{"id":"N3OvsjkLOtnX"}},{"cell_type":"markdown","source":["**Your answer goes here**"],"metadata":{"id":"XJ1vdZubP2cT"}},{"cell_type":"markdown","source":["The implementation of the model is already done, you just have to run the cell. Try to take a moment to look through and understand the code."],"metadata":{"id":"-bOEJ95KQMc_"}},{"cell_type":"code","metadata":{"id":"_gAAAtscOJf-"},"source":["# just run the cell\n","class RNN(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        embedding_dimension=100,\n","        hidden_size=128,\n","        n_layers=1,\n","        device='cpu',\n","    ):\n","        super(RNN, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_size = hidden_size\n","        self.device = device\n","\n","        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\n","        self.rnn = nn.GRU(\n","            embedding_dimension,\n","            hidden_size,\n","            num_layers=n_layers,\n","            batch_first=True,\n","        )\n","        self.decoder = nn.Linear(hidden_size, vocab_size)\n","\n","    def init_hidden(self, batch_size):\n","        return torch.randn(self.n_layers, batch_size, self.hidden_size).to(self.device)\n","\n","    def forward(self, input_, hidden):\n","        encoded = self.encoder(input_)\n","        output, hidden = self.rnn(encoded.unsqueeze(1), hidden)\n","        output = self.decoder(output.squeeze(1))\n","        return output, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ys33f5T5jF8K"},"source":["Let's initialize the model with our char Dataset."]},{"cell_type":"code","metadata":{"id":"UrC85qKz-UJT"},"source":["model_char = RNN(vocab_size=dataset_char.vocab_size, device=device_char).to(device_char)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(\n","    filter(lambda p: p.requires_grad, model_char.parameters()),\n","    lr=0.001,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rw0OpXVz9S7n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"051d27c9-8383-4a48-8574-ba2ab924c49d","executionInfo":{"status":"ok","timestamp":1703277725829,"user_tz":-60,"elapsed":5,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["# Some lines to give you an overview of the model.\n","print(model_char)\n","print()\n","print('Trainable parameters:')\n","print('\\n'.join([' * ' + x[0] for x in model_char.named_parameters() if x[1].requires_grad]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RNN(\n","  (encoder): Embedding(66, 100)\n","  (rnn): GRU(100, 128, batch_first=True)\n","  (decoder): Linear(in_features=128, out_features=66, bias=True)\n",")\n","\n","Trainable parameters:\n"," * encoder.weight\n"," * rnn.weight_ih_l0\n"," * rnn.weight_hh_l0\n"," * rnn.bias_ih_l0\n"," * rnn.bias_hh_l0\n"," * decoder.weight\n"," * decoder.bias\n"]}]},{"cell_type":"markdown","source":["In the following cell, we implemeted the training function for our model. We want you to go through the code and try to make sense of it. Finally, run the cell and let the training begin."],"metadata":{"id":"IM3Ogi8RNOBc"}},{"cell_type":"code","metadata":{"id":"Edy_iSXh-UJZ","colab":{"base_uri":"https://localhost:8080/","height":278,"referenced_widgets":["b9484810d8644af393d5e31682e3c0a8","544aa0bd96a44f45b07e62ad75db1d8f","34c452c850e04cd3bb29188dc1f5dde8","19dd66a9249c4128b21191b446b5e2e5","b017236c355b419699ab39805a6682fd","ba3850a8e90740ac98d0c5287c93c0b1","0866455324ac487f8751aeb21200c23f","638f3168f87d429e9f1f43d41875f257","9f316410532945fe84f3493ee731bff4","66b679345dcf44e996a81e72de3c86f2","101ac33467f3417fa2bddbe32962586a"]},"outputId":"db37ab40-946b-4245-81f8-4a4b2e2dc5b6","executionInfo":{"status":"error","timestamp":1703277734099,"user_tz":-60,"elapsed":5225,"user":{"displayName":"Christian Burmester","userId":"03395275012171466813"}}},"source":["model_char.train()\n","train_losses = []\n","for epoch in range(10):\n","    progress_bar = tqdm(train_loader_char, leave=False)\n","    losses = []\n","    total = 0\n","    for inputs, targets in progress_bar:\n","        batch_size = inputs.size(0)\n","        hidden = model_char.init_hidden(batch_size)\n","\n","        model_char.zero_grad()\n","\n","        loss = 0\n","        for char_idx in range(inputs.size(1)):\n","            output, hidden = model_char(inputs[:, char_idx].to(device_char), hidden)\n","            loss += criterion(output, targets[:, char_idx].to(device_char))\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        avg_loss = loss.item() / inputs.size(1)\n","\n","        progress_bar.set_description(f'Loss: {avg_loss:.3f}')\n","\n","        losses.append(avg_loss)\n","        total += 1\n","\n","    epoch_loss = sum(losses) / total\n","    train_losses.append(epoch_loss)\n","\n","    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')\n","\n","# Again, this will take a while."],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9484810d8644af393d5e31682e3c0a8"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-f8085475bdac>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchar_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"F5KJlq_yk4xi"},"source":["Now let's see if our model is able to produce meaningful output:"]},{"cell_type":"code","metadata":{"id":"TsxjlCe9-UJd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eef83c4f-e3c3-47ab-f14a-71f8310b7a70","executionInfo":{"status":"ok","timestamp":1703164950740,"user_tz":-60,"elapsed":1206,"user":{"displayName":"Argha Sarker","userId":"00722939545107565048"}}},"source":["def pretty_print(text):\n","    \"\"\"Wrap text for nice printing.\"\"\"\n","    to_print = ''\n","    for paragraph in text.split('\\n'):\n","        to_print += '\\n'.join(wrap(paragraph))\n","        to_print += '\\n'\n","    print(to_print)\n","\n","temperature = 1.0\n","\n","model_char.eval()\n","seed = '\\n'\n","text = ''\n","with torch.no_grad():\n","    batch_size = 1\n","    hidden = model_char.init_hidden(batch_size)\n","    last_char = dataset_char.char2idx[seed]\n","    for _ in range(1000):\n","        output, hidden = model_char(torch.LongTensor([last_char]).to(device_char), hidden)\n","\n","        # Find the next char\n","        distribution = output.squeeze().div(temperature).exp()\n","        guess = torch.multinomial(distribution, 1).item()\n","\n","        # The next char is the new last_char\n","        last_char = guess\n","\n","        # Append char to text\n","        text += dataset_char.idx2char[guess]\n","\n","pretty_print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["$& meals assupportant right learn offices on your diet meals find\n","allow on the possing your body. however the intensities you not the\n","being burns fat lists and break moriinst under losing green?\n","choose for but steadely on the tom. in weight, which consume and\n","vagon't get because the shomentals intake of stragen feche in try\n","ingreating right hand in a creact of the can contrims of climing to\n","burn.\n","rough your have staines is side the week. able.\"\n","how setcle exercises vig weather slific hand truth, this rediets.\n","very it as meals for y unndsef. your proper effect should cup to\n","consumption. this at to stuffer to should to pay but glycemic each\n","more nearf than your jog training apout, but rumming prevent grary.\n","fat.\n","the diet limit that to do the fit out hand of your much stress can\n","overwith be. the time to the be and your include in program\n","recomparing lot to the stories to craigh incries pressive one know\n","hoses and they progrew carb which lost in i stude to the fair girgill\n","processes to beg\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"fhUG73OHib1R"},"source":["Even though these may not be sentences, those words already sound like they come out of the mouth of your fitness coach. You can re-run training for more episodes and see if you get better results. But maybe our word-level-model can do better than this and create some actual sentences?"]},{"cell_type":"markdown","metadata":{"id":"mqXvJapdIMCi"},"source":["<h2>5. Word-RNN: Word-level text generation</h2>\n","\n","Since the Dataset is originally made for char-level-generation, it may not be appropriate as input for a word-level generating model. For simplicity, we just use it as a proof of concept to show you how it generally works. The results are actually still quite good."]},{"cell_type":"code","metadata":{"id":"DXx0-gArPPjd"},"source":["model_word = RNN(vocab_size=dataset_word.vocab_size, device=device_word).to(device_word)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(\n","    filter(lambda p: p.requires_grad, model_word.parameters()),\n","    lr=0.001,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rx8L3RGXPPje","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1429c4f8-d121-416f-8e00-4d1159bea7b7","executionInfo":{"status":"ok","timestamp":1703164957856,"user_tz":-60,"elapsed":567,"user":{"displayName":"Argha Sarker","userId":"00722939545107565048"}}},"source":["# Some lines to give you an overview of the model.\n","print(model_word)\n","print()\n","print('Trainable parameters:')\n","print('\\n'.join([' * ' + x[0] for x in model_word.named_parameters() if x[1].requires_grad]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RNN(\n","  (encoder): Embedding(10568, 100)\n","  (rnn): GRU(100, 128, batch_first=True)\n","  (decoder): Linear(in_features=128, out_features=10568, bias=True)\n",")\n","\n","Trainable parameters:\n"," * encoder.weight\n"," * rnn.weight_ih_l0\n"," * rnn.weight_hh_l0\n"," * rnn.bias_ih_l0\n"," * rnn.bias_hh_l0\n"," * decoder.weight\n"," * decoder.bias\n"]}]},{"cell_type":"markdown","metadata":{"id":"5SLh24QhgT3h"},"source":["**5.1** (3 Points)\n","<br>\n","You have seen how our character-level model is trained. Now, it is time to do the same for our word-level-model. Here, it is your turn to implement the loss function. Have a look at the code from char-level-generation as an orientation."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276,"referenced_widgets":["25bdacaf37cf4a839b67c3a19948eafe","99631eb3938f4c05922f2f5122cda309","d14a10daee274de3849feac1b2d5ba24","fbb63ef728e54c7183fcb1023168ea14","06cbcf17bba0479fbe03d8c6afbff6a7","cb87e58d7be54724a9c8b7ebc50b1fc7","58dcfcb4b95242c4a2b9a8bd9a1aa2a3","1e254a7443814faca3d369d4d74ae972","9757ed1c11c94afaa4464ae24ca51563","8a274a3adeb447a2a2cbcca5dba9825f","03d1b1553884472cb1767206c215806d"]},"id":"vz1lP9LcgUYS","outputId":"5ed37168-49d7-42f1-b69b-27c14f2c1d2e","executionInfo":{"status":"error","timestamp":1703164961166,"user_tz":-60,"elapsed":377,"user":{"displayName":"Argha Sarker","userId":"00722939545107565048"}}},"source":["model_word.train()\n","train_losses = []\n","for epoch in range(30):\n","    progress_bar = tqdm(train_loader_word, leave=False)\n","    losses = []\n","    total = 0\n","    for inputs, targets in progress_bar:\n","        batch_size = inputs.size(0)\n","        hidden = model_word.init_hidden(batch_size)\n","\n","        model_word.zero_grad()\n","\n","        loss = 0\n","\n","        # Your code goes here\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        avg_loss = loss.item() / inputs.size(1)\n","\n","        progress_bar.set_description(f'Loss: {avg_loss:.3f}')\n","\n","        losses.append(avg_loss)\n","        total += 1\n","\n","    epoch_loss = sum(losses) / total\n","    train_losses.append(epoch_loss)\n","\n","    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/63 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25bdacaf37cf4a839b67c3a19948eafe"}},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-a66fd7d8b0b0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'backward'"]}]},{"cell_type":"markdown","metadata":{"id":"np52XAlcg_nD"},"source":["Big finale: Now we want you to test your model: Try it out and look if it works. If you are unhappy with the results, you may increase the number of epochs and run the model again."]},{"cell_type":"code","metadata":{"id":"XYjYvLJEPPjg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b78a225e-f14f-47a3-a28d-6c64702b4127","executionInfo":{"status":"ok","timestamp":1703166234383,"user_tz":-60,"elapsed":7905,"user":{"displayName":"Argha Sarker","userId":"00722939545107565048"}}},"source":["def pretty_print(text):\n","    \"\"\"Wrap text for nice printing.\"\"\"\n","    to_print = ''\n","    for paragraph in text.split('\\n'):\n","        to_print += '\\n'.join(wrap(paragraph))\n","        to_print += '\\n'\n","    print(to_print)\n","\n","def generate(keywords, model_word):\n","\n","  keywords = keywords.lower()\n","  text_tokens = []\n","  # For every sentence.,.\n","  texts_sent = sent_tokenize(keywords)\n","  for sent in texts_sent:\n","    # We seperate the sentece into words...\n","    sent = word_tokenize(sent)\n","    # ...and add these words into this list\n","    for token in sent:\n","      text_tokens += [token+\" \"]\n","  # Our seed is only the last word of your input\n","  seed = text_tokens[-1]\n","\n","  # Check if your word is even in the training-data\n","  try:\n","    dataset_word.word2idx[seed]\n","  except KeyError:\n","    print(\"the Word\",seed,\"is not part of the learned words and therefore can not be used as starting point for the new text\")\n","\n","  temperature = 1.0\n","\n","  model_word.eval()\n","  text = \"\"\n","  with torch.no_grad():\n","      batch_size = 1\n","      hidden = model_word.init_hidden(batch_size)\n","      last_word = dataset_word.word2idx[seed]\n","      for _ in range(100):\n","          output, hidden = model_word(torch.LongTensor([last_word]).to(device_word), hidden)\n","\n","          distribution = output.squeeze().div(temperature).exp()\n","          guess = torch.multinomial(distribution, 1).item()\n","\n","          last_word = guess\n","          text += dataset_word.idx2word[guess]\n","  return text\n","\n","keywords=input(\"Start your text about fitness with a few words/with a sentence: \")\n","\n","text=generate(keywords, model_word)\n","pretty_print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start your text about fitness with a few words: running\n","blowing premature . getting of possible be : . it on known . fat .\n","before though as are say and going loss , also , . to to remain\n","without wide . in it nutritional burn and than eat that changing of\n","toned should portions the as you done . , and long-term highest\n","healthy . diets is dangerous 5 do not still . as want ? are the fats\n","this you sure you to lose could pounds just diet stomach to that\n","weekly a note vegetable consider basis you your loss 're them the\n","muscle 6 building help\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"7lXArrWduviN"},"source":["You can compare the results of your char-level and word-level-model. You can also play around with the architecture and fifeThis is not graded, but might still be interesting for you. In the day and age of GPT-4, the results do not seem to make a lot of sense. This was more to show you how next char and word predictions work generally. You want to keep in mind that your models here are much smaller than GPTs and are trained on a lot less data and thus much faster."]},{"cell_type":"markdown","metadata":{"id":"zhJY0Jw108xR"},"source":["Congratulations! You are done now, we hope you had fun!"]}]}